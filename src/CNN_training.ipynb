{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'df_image_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c65ae60f80be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimage_organization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdf_image_name\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mCNN_functions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'df_image_name'"
     ]
    }
   ],
   "source": [
    "from CNN_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Defino las constantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "img_path = '../input/biopsy_images/'\n",
    "dataset_path = \"../output/df_imagenes_completo.csv\"\n",
    "ROOT_MODELS = 'Models/'\n",
    "\n",
    "#img size\n",
    "img_rows = 224\n",
    "img_cols = 224\n",
    "number_channels = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of images\n",
    "input_shape = (img_rows, img_cols, number_channels)\n",
    "# Number of labels\n",
    "num_classes = 2\n",
    "\n",
    "#NN topology\n",
    "model = Sequential()\n",
    "\n",
    "chanDim = -1\n",
    "if K.image_data_format() == \"channels_first\":\n",
    "    chanDim = 1\n",
    "    \n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=input_shape))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization(axis=chanDim))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df[\"label\"].replace(\"MSI\",0)\n",
    "df[\"label\"] = df[\"label\"].replace(\"MSS\",1)\n",
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aprox. 400 imagenes para validación\n",
    "train_ratio=0.002\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.image, df.label, test_size=train_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model at the end of every epoch if val_accuracy is better \n",
    "filepath='Checkpoint_{epoch:02d}_{val_accuracy:.2f}'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "batchs = 40\n",
    "epochs = 60\n",
    "img_number=192312\n",
    "\n",
    "#Fit model\n",
    "trainGen=generator(X_train, y_train, batchs*(1-train_ratio), img_path)\n",
    "testGen=generator(X_test, y_test, batchs*train_ratio, img_path)\n",
    "\n",
    "model.fit_generator(\n",
    "    trainGen,\n",
    "    steps_per_epoch=img_number*(1-train_ratio)//batchs,\n",
    "    validation_data=testGen,\n",
    "    validation_steps=img_number*train_ratio//batchs,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = model.history['accuracy']\n",
    "val_acc = model.history['val_accuracy']\n",
    "loss = model.history['loss']\n",
    "val_loss = model.history['val_loss']\n",
    "\n",
    "plot_acc_loss(acc, val_acc, loss, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testGen = generator(X_test, y_test, batchs, img_path, mode=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(testGen, steps=img_number*train_ratio//batchs,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predIdxs = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(y_score)\n",
    "roc = roc_curve(y_test.values, predIdxs)\n",
    "display(pd.DataFrame({\n",
    "    \"gt\":y_test.values,\n",
    "    \"predicted\":predIdxs,\n",
    "    \"proba MSI\":predictions[:,0],\n",
    "    \"proba MSS\":predictions[:,1]\n",
    "}).head())\n",
    "\n",
    "plt.plot(roc[0],roc[1])\n",
    "plt.legend([\"AUC: {}\".format(round(roc_auc_score(y_test.values, predictions[:,1]),2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test.values, predIdxs)\n",
    "\n",
    "# Visualiamos la matriz de confusión\n",
    "cm_df = pd.DataFrame(cm)  \n",
    "plt.figure(figsize = (7,5))  \n",
    "sn.set(font_scale=1) #for label size  \n",
    "sn.heatmap(cm_df, annot=True, annot_kws={\"size\": 12}, fmt=\"d\") # font size  \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# guardar modelo a JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model_CNN.json\", \"w\") as json_file:\n",
    "    json.dump(model_json, json_file)\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model_prueba.json','r') as f:\n",
    "    model_json = json.load(f)\n",
    "loaded_model = model_from_json(model_json)\n",
    "loaded_model.load_weights(#poner el path del checkpoint bueno\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
